\chapter{Rule Based Models}

A rule based classifier is a model that uses a \textbf{rule set} of ``if-then'' rules to classify instances. Each rule is expressed in the form:
\begin{equation*}
    r_i : (Cond_i) \xrightarrow{} y_i.
\end{equation*}
The left side contains a conjunction of attribute test conditions, and is called \textbf{antecedent} or \textbf{precondition}, while the right side represents the predicted class, and is called the \textbf{consequent}. Each condition is defined by a set of $k$ attribute-value pairs, such that:
\begin{equation*}
    Cond_i = (A_1 op v_1) \land (A_2 op v_2) \land \dots \land (A_k op v_k) \ ,
\end{equation*}
where $op$ is a comparison operator. Each attribute test is also known as a \textbf{conjunct}.

A rule $r$ \textbf{covers} an instance $x$ if the attributes of the instance satisfy the antecedent of the rule. Consider the following dataset:
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        Name & Can Fly & Gives Birth & Blood Type \\
    \hline
    \hline
        Bat & Y & Y & W \\
    \hline
        Owl & Y & N & W \\
    \hline
        Crocodile & N & N & C \\
    \hline
        Platypus & N & N & W \\
    \hline
    \end{tabular}
    \caption{Small example dataset.}
    \label{tab:small_dataset}
\end{table}
\\The rule $(Can Fly = Y) \land (Gives Birth = N) \xrightarrow{} Bird$ covers the instance ``Owl''.

The \textbf{coverage} of a rule is the fraction of records in the whole dataset that are covered by it. The \textbf{accuracy} (sometimes called \textbf{precision}) of a rule is the fraction of records in the dataset that satisfy the antecedent that also satisfy the consequent.
\BoxDef{Coverage and Accuracy}{
\begin{align*}
    &Coverage(r) = \dfrac{|A|}{|D|} \\\\
    &Accuracy(r) = \dfrac{|A \cap y|}{|A|}
\end{align*}
}

\section{How Rule-Based Models Work}

A rule based classifier classifies a test instance based on the rule triggered by the instance. Looking at the dataset pictured in Table \ref{tab:small_dataset}, assume we obtained the following rule set from a training set:
\begin{align*}
    &r_1 : (Can Fly = Y) \xrightarrow{} Bird \\
    &r_2 : (Gives Birth = Y) \land (Blood Type = W) \xrightarrow{} Mammal \\
    &r_3 : (Blood Type = C) \xrightarrow{} Reptile
\end{align*}
The instance Owl triggers the first rule, and is therefore classified as a $Bird$. The Bat triggers both the first and the second rule, which produce conflicting outcomes. None of the rules cover the example Platypus, so there's no immediate way to assign a class to this animal. The following section will explain how these issues can be solved.

\section{Properties of a Rule Set}

The rule set generated by the model can be characterized by the following two properties:
\BoxDef{Mutually Exclusive Rule Set}{
The rules in a rule set $R$ are mutually exclusive if no two rules in $R$ are triggered by the same instance; this property guarantees that each instance is covered by at most one rule in $R$.
}
\BoxDef{Exhaustive Rule Set}{
A rule set $R$ is exhaustive if each combination of attribute values is covered by at least one rule.
}
Unfortunately, many rule based classifiers do not have such properties. If the rule set is not exhaustive, a default rule with an empty antecedent can be added to classify all instances that are not covered by any other rule.

If the rule set is not mutually exclusive, the rules can be organized into an \textbf{ordered rule set} (also known as \textbf{decision list}).
\BoxDef{Ordered Rule Set}{
The rules in an ordered rule set $R$ are ranked in decreasing order of priority. 
}
The rank of the rule can be defined via either \textbf{rule-based ordering} (rules are ranked based on their quality, e.g., their accuracy) or \textbf{class-based ordering} (all rules that have the same consequent appear together). When a test instance is presented to the model, it is compared with the rules starting from the one at the top of the ranking, and the prediction will be the one appearing as the consequent of the highest ranking rule that covers the instance. If none of the rules are triggered, the default rule is reached, classifying the instance as the default class.

Another approach is to use a \textbf{voting scheme}, where, for each test instance, votes are accumulated for each class assigned to it by the rules it triggers. The prediction will correspond to the class with the highest number of votes, and votes may also be weighted depending on the rule that is producing it (for example, rules with lower accuracy will produce votes with lower weight).

The advantage of using an unordered rule set is that they're less susceptible to errors, since they are not biased by the chosen ordering. Model building is also less expensive, since the rules don't have to be sorted. On the other hand, classification can be more costly, since the same instance must be first compared to all the rules in the rule set before evaluating the votes.

\section{Building a Rule Set}

Rule extraction methods can be either:
\begin{itemize}
    \item \textbf{Direct}, if the rules are extracted from the data itself;
    \item \textbf{Indirect}, if the rules are extracted from some other model (e.g., Decision Trees).
\end{itemize}

\subsection{Direct Methods for Rule Extraction}

